//! LLM Retry Simulation
//!
//! This example simulates various failure scenarios to demonstrate
//! the robustness of the LLM client's retry and error handling mechanisms.

use sage_core::{
    config::provider::ProviderConfig,
    error::SageError,
    llm::{
        LlmProvider, TimeoutConfig, client::LlmClient, messages::LlmMessage,
        provider_types::ModelParameters,
    },
};
use std::time::Instant;
use tracing_subscriber::fmt::init;
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—ï¼Œè®¾ç½®ä¸ºWARNçº§åˆ«ä»¥çœ‹åˆ°é‡è¯•æ—¥å¿—
    init();

    println!("ğŸ”„ Sage Agent é‡è¯•æœºåˆ¶æ¼”ç¤º");
    println!("==========================");

    // åˆ›å»ºä¸€ä¸ªé…ç½®ï¼Œä½¿ç”¨æ— æ•ˆçš„APIå¯†é’¥æ¥æ¨¡æ‹Ÿé”™è¯¯
    let provider_config = ProviderConfig::new("google")
        .with_api_key("invalid-api-key-for-testing")
        .with_timeouts(TimeoutConfig::new().with_request_timeout_secs(10))
        .with_max_retries(3);

    let model_params = ModelParameters::new("gemini-2.5-pro")
        .with_max_tokens(100)
        .with_temperature(0.7);

    let client = LlmClient::new(LlmProvider::Google, provider_config, model_params.clone())?;

    let messages = vec![LlmMessage::user("Hello, this is a test message.")];

    println!("\nğŸ“¡ æµ‹è¯•1: ä½¿ç”¨æ— æ•ˆAPIå¯†é’¥ï¼ˆåº”è¯¥ä¸ä¼šé‡è¯•ï¼‰");
    let start = Instant::now();
    match client.chat(&messages, None).await {
        Ok(_) => println!("âœ… æ„å¤–æˆåŠŸ"),
        Err(error) => {
            let duration = start.elapsed();
            println!("âŒ å¤±è´¥ï¼ˆé¢„æœŸï¼‰: {}", error);
            println!("â±ï¸  è€—æ—¶: {:?}", duration);

            // æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯ï¼ˆä¸åº”è¯¥é‡è¯•ï¼‰
            if let SageError::Llm { message: msg, .. } = &error {
                if msg.contains("401") || msg.contains("403") || msg.contains("API key") {
                    println!("âœ… æ­£ç¡®ï¼šè®¤è¯é”™è¯¯æ²¡æœ‰è§¦å‘é‡è¯•");
                }
            }
        }
    }

    println!("\nğŸ“¡ æµ‹è¯•2: ä½¿ç”¨æœ‰æ•ˆAPIå¯†é’¥ä½†å¯èƒ½é‡åˆ°æœåŠ¡è¿‡è½½");

    // ä½¿ç”¨çœŸå®çš„APIå¯†é’¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    let real_config = ProviderConfig::new("google")
        .with_api_key("AIzaSyCtI947T9sCiW6fMob6Sipt8l0JfGFS_U4")
        .with_timeouts(TimeoutConfig::new().with_request_timeout_secs(30))
        .with_max_retries(2);

    let real_client = LlmClient::new(LlmProvider::Google, real_config, model_params)?;

    let start = Instant::now();
    match real_client.chat(&messages, None).await {
        Ok(response) => {
            let duration = start.elapsed();
            println!("âœ… è¯·æ±‚æˆåŠŸ!");
            println!(
                "ğŸ“ å“åº”: {}",
                response.content.chars().take(100).collect::<String>()
            );
            println!("â±ï¸  è€—æ—¶: {:?}", duration);
        }
        Err(error) => {
            let duration = start.elapsed();
            println!("âŒ è¯·æ±‚å¤±è´¥: {}", error);
            println!("â±ï¸  æ€»è€—æ—¶: {:?}", duration);

            // æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
            if let SageError::Llm { message: msg, .. } = &error {
                if msg.contains("503") || msg.contains("overloaded") || msg.contains("429") {
                    println!("âœ… æ­£ç¡®ï¼šæœåŠ¡è¿‡è½½é”™è¯¯è§¦å‘äº†é‡è¯•æœºåˆ¶");
                }
            }
        }
    }

    println!("\nğŸ“Š é‡è¯•æœºåˆ¶æ€»ç»“:");
    println!("- âœ… æŒ‡æ•°é€€é¿å»¶è¿Ÿç­–ç•¥");
    println!("- âœ… æ™ºèƒ½é”™è¯¯åˆ†ç±»");
    println!("- âœ… å¯é…ç½®é‡è¯•æ¬¡æ•°");
    println!("- âœ… è¯¦ç»†çš„æ—¥å¿—è®°å½•");
    println!("- âœ… éé˜»å¡å¼‚æ­¥å®ç°");

    Ok(())
}
